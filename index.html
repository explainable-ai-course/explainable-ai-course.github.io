<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>XAI Course</title>
  <link rel="stylesheet" href="styles.css"> <!-- Link to styles.css -->
</head>
<body>
<header>
  <div class="header-content">
    <img src="images/full_white_transparent_logo.png" alt="XAI Logo" class="logo"> <!-- Adjust the path if needed -->
    <div>
      <h1>Welcome to the Explainable AI Module</h1>
      <h2>PCS956 - Research Trends in Applied Machine Learning</h2>
    </div>
  </div>
</header>


<div class="main-container">

  <nav class="sidebar">
    <ul>
      <li><a href="index.html"><strong>Home</strong></a></li>
      <li><a href="assignments.html"><strong>Assignments</strong></a></li>
      <li><a href="resources.html"><strong>Resources</strong></a></li>
      <li><a href="contact.html"><strong>Contact</strong></a></li>
    </ul>
  </nav>

  <main>
    <h2>Lecture Schedule</h2>

    <table>
      <thead>
        <tr>
          <th>Week</th>
          <th>Topic</th>
          <th>Course Material</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Week 1</strong></td>
          <td><strong>Introduction to Explainable AI (XAI) and its Taxonomy</strong></td>
          <td>
          <strong>Lectures:</strong> <a href="https://docs.google.com/presentation/d/12qxcPlUEyCkzUsHegx7cBjSMUtayPmv9/edit?usp=sharing&ouid=115388823773414547585&rtpof=true&sd=true"> Introduction to Explainable AI (XAI) and its Taxonomy </a><br><br> <!-- Added extra line break for space -->
          
          <strong>Readings:</strong><br>
          Molnar, 2024, <a href="https://christophm.github.io/interpretable-ml-book/" style="color: blue;">Interpretable Machine Learning, A Guide for Making Black Box Models Explainable</a><br>
          Murdoch et al., 2019, <a href="https://www.pnas.org/doi/10.1073/pnas.1900654116" style="color: blue;">Definitions, methods, and applications in interpretable machine learning</a><br>
          Lipton, 2017, <a href="https://arxiv.org/pdf/1606.03490" style="color: blue;">The Mythos of Model Interpretability</a><br>
          Doshi-Velez and Kim, 2017, <a href="https://arxiv.org/pdf/1702.08608" style="color: blue;">Towards A Rigorous Science of Interpretable Machine Learning</a><br>
          Murdoch et al., 2019, <a href="https://arxiv.org/pdf/1901.04592v1" style="color: blue;">Interpretable Machine Learning: Definitions, Methods, and Applications</a><br>
          Weller, 2019, <a href="https://arxiv.org/pdf/1708.01870" style="color: blue;">Transparency: Motivations and Challenges</a><br>
          Zhanget al., 2018, <a href="https://arxiv.org/abs/1802.00121" style="color: blue;">Interpreting CNNs via Decision Trees</a><br>
         
            
            
            
          <br>
          
          <strong>Python Notebooks:</strong> <a href="https://colab.research.google.com/drive/1TCaO8f5GhnuKPY5puDpjatUoLh6EGg3V?usp=sharing"> Intrinsic vs. Posthoc Explanations </a>, </strong> <a href="https://drive.google.com/file/d/1rANrHQUSm6Ahf1gt-EvACt0pMMTPzOEM/view?usp=sharing"> Global vs. Local Explanations </a>,
          </strong> <a href="https://drive.google.com/file/d/16cSz9m9ijsowb4k_6_FTc4kByOu9uie2/view?usp=sharing"> Exercise 1 </a>, </strong> <a href="https://colab.research.google.com/drive/1D4Ahj71kenj_UoI7Awe6cAyvioaCMzY5?usp=sharing"> Exercise 2 </a>

          </td>
        </tr>
        <tr>
          <td><strong>Week 2</strong></td>
          <td><strong>Trade-offs Between Accuracy and Explainability in ML Models</strong></td>
          <td>
          <strong>Lectures:</strong> <a href="#"></a><br><br> <!-- Added extra line break for space -->
          
          <strong>Readings:</strong><br>
          Jabbari et al., 2020, <a href="https://teamcore.seas.harvard.edu/files/teamcore/files/2020_jabbari_paper_32.pdf" style="color: blue;">An Empirical Study of the Trade-Offs Between Interpretability and Fairness</a><br>  
          Slack et. al., 2020, <a href="https://arxiv.org/abs/1911.02508" style="color: blue;">Fooling LIME and SHAP</a><br>
          Agarwal et. al., 2023, <a href="https://arxiv.org/abs/2206.11104" style="color: blue;">OpenXAI: Towards a Transparent Evaluation of Model Explanations</a><br>  
          Dziugaite et. al., 2020, <a href="https://arxiv.org/abs/2010.13764" style="color: blue;">Enforcing interpretability and its statistical impacts: Trade-offs between accuracy and interpretability</a><br>    
          Rudin, 2019, <a href="https://www.nature.com/articles/s42256-019-0048-x" style="color: blue;">Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead</a><br>
          Haseet al., 2020, <a href="https://arxiv.org/pdf/2005.01831" style="color: blue;">Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?</a><br>
            
          <br>
          <strong>Python Notebooks:
            <br>
          <strong>Data:
          </strong> <a href="https://drive.google.com/file/d/1S4SbQgJlLSefypIUTnsFPoc6NqoKJJVP/view?usp=sharing"> Dataset</a>
          </strong> <a href="https://drive.google.com/file/d/1S4SbQgJlLSefypIUTnsFPoc6NqoKJJVP/view?usp=sharing"> Image</a>
          </td>
        </tr>
        <tr>
          <td><strong>Week 3</strong></td>
          <td><strong>XAI Methods and Evaluation of Explainability</strong></td>
          <td>
          <strong>Lectures:</strong> <a href="#"></a><br><br> <!-- Added extra line break for space -->
          
          <strong>Readings:</strong><br>
          Longo et al., 2024, <a href="https://www.sciencedirect.com/science/article/pii/S1566253524000794" style="color: blue;">Explainable Artificial Intelligence (XAI) 2.0: A manifesto of open challenges and interdisciplinary research directions</a><br>
          Datcu et al., 2023, <a href="https://drive.google.com/file/d/17ysHnxox44qYGxKvxJkm5tIvFqNULsvb/view?usp=sharing" style="color: blue;">Explainable, Physics-Aware, Trustworthy Artificial Intelligence: A paradigm shift for synthetic aperture radar</a><br>

          <br>  
          <strong>Python Notebooks:</strong> <a href="#"></a>
          </td>
        </tr>
      </tbody>
    </table>
  </main>
</div>

<footer>
  <p>&copy; Mehak Khan 2024</p>
</footer>
</body>
</html>
